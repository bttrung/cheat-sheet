{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6_Saving and Loading Models.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bttrung/secure-private-ai-scholarship/blob/master/6_Saving_and_Loading_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B73gMgzuEbw0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import helper\n",
        "import fc_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU5rhMxlEqgt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "eef4732e-41ee-4913-ecb3-27ca83fbefcc"
      },
      "source": [
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,))])\n",
        "# Download and load the training data\n",
        "trainset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Download and load the test data\n",
        "testset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "26427392it [00:02, 11056003.40it/s]                             \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting F_MNIST_data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 75114.25it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting F_MNIST_data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4423680it [00:01, 3036304.01it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting F_MNIST_data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 25439.11it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting F_MNIST_data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9drpLVYXFqei",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "73eb1cf6-c640-46f0-8068-a43b63a28f95"
      },
      "source": [
        "image, label = next(iter(trainloader))\n",
        "helper.imshow(image[0,:]);"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdMAAAHTCAYAAAB8/vKtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmO4cAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 233,
              "height": 233
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NWrBBZTFttB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the network, define the criterion and optimizer\n",
        "\n",
        "model = fc_model.Network(784, 10, [512, 256, 128])\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDGt4wbOFwID",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "75e2decc-3f96-4929-a84e-aee0ed4af4a9"
      },
      "source": [
        "fc_model.train(model, trainloader, testloader, criterion, optimizer, epochs=2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/2..  Training Loss: 1.705..  Test Loss: 1.028..  Test Accuracy: 0.601\n",
            "Epoch: 1/2..  Training Loss: 1.038..  Test Loss: 0.753..  Test Accuracy: 0.724\n",
            "Epoch: 1/2..  Training Loss: 0.892..  Test Loss: 0.677..  Test Accuracy: 0.740\n",
            "Epoch: 1/2..  Training Loss: 0.778..  Test Loss: 0.650..  Test Accuracy: 0.752\n",
            "Epoch: 1/2..  Training Loss: 0.722..  Test Loss: 0.636..  Test Accuracy: 0.757\n",
            "Epoch: 1/2..  Training Loss: 0.722..  Test Loss: 0.614..  Test Accuracy: 0.768\n",
            "Epoch: 1/2..  Training Loss: 0.703..  Test Loss: 0.580..  Test Accuracy: 0.780\n",
            "Epoch: 1/2..  Training Loss: 0.670..  Test Loss: 0.557..  Test Accuracy: 0.795\n",
            "Epoch: 1/2..  Training Loss: 0.670..  Test Loss: 0.553..  Test Accuracy: 0.798\n",
            "Epoch: 1/2..  Training Loss: 0.612..  Test Loss: 0.590..  Test Accuracy: 0.784\n",
            "Epoch: 1/2..  Training Loss: 0.662..  Test Loss: 0.549..  Test Accuracy: 0.799\n",
            "Epoch: 1/2..  Training Loss: 0.633..  Test Loss: 0.518..  Test Accuracy: 0.808\n",
            "Epoch: 1/2..  Training Loss: 0.602..  Test Loss: 0.533..  Test Accuracy: 0.807\n",
            "Epoch: 1/2..  Training Loss: 0.629..  Test Loss: 0.508..  Test Accuracy: 0.809\n",
            "Epoch: 1/2..  Training Loss: 0.546..  Test Loss: 0.504..  Test Accuracy: 0.813\n",
            "Epoch: 1/2..  Training Loss: 0.605..  Test Loss: 0.506..  Test Accuracy: 0.815\n",
            "Epoch: 1/2..  Training Loss: 0.582..  Test Loss: 0.491..  Test Accuracy: 0.817\n",
            "Epoch: 1/2..  Training Loss: 0.562..  Test Loss: 0.495..  Test Accuracy: 0.820\n",
            "Epoch: 1/2..  Training Loss: 0.577..  Test Loss: 0.492..  Test Accuracy: 0.820\n",
            "Epoch: 1/2..  Training Loss: 0.644..  Test Loss: 0.517..  Test Accuracy: 0.814\n",
            "Epoch: 1/2..  Training Loss: 0.571..  Test Loss: 0.499..  Test Accuracy: 0.816\n",
            "Epoch: 1/2..  Training Loss: 0.552..  Test Loss: 0.468..  Test Accuracy: 0.828\n",
            "Epoch: 1/2..  Training Loss: 0.564..  Test Loss: 0.482..  Test Accuracy: 0.824\n",
            "Epoch: 2/2..  Training Loss: 0.595..  Test Loss: 0.488..  Test Accuracy: 0.818\n",
            "Epoch: 2/2..  Training Loss: 0.534..  Test Loss: 0.461..  Test Accuracy: 0.828\n",
            "Epoch: 2/2..  Training Loss: 0.580..  Test Loss: 0.483..  Test Accuracy: 0.817\n",
            "Epoch: 2/2..  Training Loss: 0.519..  Test Loss: 0.473..  Test Accuracy: 0.830\n",
            "Epoch: 2/2..  Training Loss: 0.531..  Test Loss: 0.474..  Test Accuracy: 0.823\n",
            "Epoch: 2/2..  Training Loss: 0.531..  Test Loss: 0.463..  Test Accuracy: 0.830\n",
            "Epoch: 2/2..  Training Loss: 0.531..  Test Loss: 0.481..  Test Accuracy: 0.820\n",
            "Epoch: 2/2..  Training Loss: 0.531..  Test Loss: 0.467..  Test Accuracy: 0.828\n",
            "Epoch: 2/2..  Training Loss: 0.564..  Test Loss: 0.471..  Test Accuracy: 0.827\n",
            "Epoch: 2/2..  Training Loss: 0.550..  Test Loss: 0.473..  Test Accuracy: 0.832\n",
            "Epoch: 2/2..  Training Loss: 0.529..  Test Loss: 0.456..  Test Accuracy: 0.836\n",
            "Epoch: 2/2..  Training Loss: 0.508..  Test Loss: 0.462..  Test Accuracy: 0.830\n",
            "Epoch: 2/2..  Training Loss: 0.513..  Test Loss: 0.447..  Test Accuracy: 0.834\n",
            "Epoch: 2/2..  Training Loss: 0.517..  Test Loss: 0.452..  Test Accuracy: 0.835\n",
            "Epoch: 2/2..  Training Loss: 0.541..  Test Loss: 0.451..  Test Accuracy: 0.835\n",
            "Epoch: 2/2..  Training Loss: 0.527..  Test Loss: 0.458..  Test Accuracy: 0.829\n",
            "Epoch: 2/2..  Training Loss: 0.523..  Test Loss: 0.456..  Test Accuracy: 0.834\n",
            "Epoch: 2/2..  Training Loss: 0.544..  Test Loss: 0.462..  Test Accuracy: 0.832\n",
            "Epoch: 2/2..  Training Loss: 0.530..  Test Loss: 0.446..  Test Accuracy: 0.840\n",
            "Epoch: 2/2..  Training Loss: 0.498..  Test Loss: 0.431..  Test Accuracy: 0.841\n",
            "Epoch: 2/2..  Training Loss: 0.496..  Test Loss: 0.440..  Test Accuracy: 0.839\n",
            "Epoch: 2/2..  Training Loss: 0.489..  Test Loss: 0.444..  Test Accuracy: 0.835\n",
            "Epoch: 2/2..  Training Loss: 0.525..  Test Loss: 0.452..  Test Accuracy: 0.835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZ-B1gvDFxpB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3f60d7a9-fa3d-4ab7-9eca-1666fe4eb1ab"
      },
      "source": [
        "print(\"Our model: \\n\\n\", model, '\\n')\n",
        "print(\"The state dict keys: \\n\\n\", model.state_dict().keys())\n",
        "print(\"The state dict values: \\n\\n\", model.state_dict().values())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our model: \n",
            "\n",
            " Network(\n",
            "  (hidden_layers): ModuleList(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
            "    (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  )\n",
            "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.5)\n",
            ") \n",
            "\n",
            "The state dict keys: \n",
            "\n",
            " odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n",
            "The state dict values: \n",
            "\n",
            " odict_values([tensor([[ 0.0413, -0.0040,  0.0422,  ..., -0.0160,  0.0254, -0.0012],\n",
            "        [-0.0023, -0.0489, -0.0195,  ..., -0.0297, -0.0022, -0.0603],\n",
            "        [-0.0182,  0.0066,  0.0046,  ...,  0.0667, -0.0078,  0.0091],\n",
            "        ...,\n",
            "        [ 0.0059,  0.0067,  0.0472,  ..., -0.0338,  0.0138,  0.0549],\n",
            "        [-0.0009, -0.0195, -0.0191,  ..., -0.0387,  0.0257, -0.0300],\n",
            "        [ 0.0021, -0.0137,  0.0443,  ...,  0.0335,  0.0007,  0.0024]]), tensor([-1.5825e-02,  4.0396e-02, -2.3840e-02, -3.7578e-02, -4.6464e-02,\n",
            "        -5.1182e-02, -4.4144e-04, -4.5156e-02, -6.9617e-02, -3.0586e-02,\n",
            "        -3.0697e-02, -2.0059e-02, -3.1707e-02, -3.5056e-04,  1.5393e-03,\n",
            "        -1.3804e-02, -1.7401e-02, -1.4748e-02,  3.6776e-02, -4.9117e-02,\n",
            "        -1.7071e-03, -2.8935e-02, -1.9610e-02, -4.3237e-02,  7.5918e-03,\n",
            "        -1.7830e-02, -1.8587e-02, -3.5587e-02, -7.3924e-03,  2.2814e-03,\n",
            "         8.9883e-03,  4.8786e-03, -2.2376e-02, -5.4385e-04,  1.1227e-02,\n",
            "        -2.4011e-03, -3.0830e-02, -4.4328e-02,  1.6737e-02, -3.7003e-02,\n",
            "        -1.0341e-02, -5.1701e-02, -5.6552e-02, -4.1918e-02,  1.4349e-02,\n",
            "        -2.5031e-02, -4.1522e-03, -1.0951e-02, -7.5055e-03, -4.3162e-02,\n",
            "        -4.1793e-02, -2.1120e-04, -4.3789e-02, -1.2757e-02,  2.5978e-02,\n",
            "        -3.0117e-02,  1.5181e-02, -2.1514e-02, -3.3134e-02, -4.7797e-02,\n",
            "         3.8486e-04, -2.3650e-04,  2.1886e-03, -4.2902e-02,  2.8771e-02,\n",
            "        -6.7263e-02,  3.4001e-03, -1.4509e-02, -5.2922e-02, -7.9219e-02,\n",
            "         1.2914e-02, -9.6256e-03, -1.4432e-02, -3.8618e-02, -3.3280e-02,\n",
            "         2.5534e-03,  5.4335e-03,  5.7483e-03, -3.1164e-02, -2.2249e-02,\n",
            "        -2.5089e-02, -4.3578e-02,  3.1830e-03,  8.9977e-03,  2.3909e-03,\n",
            "        -4.3666e-02, -5.2809e-02, -3.8158e-02, -3.3381e-02, -5.8959e-02,\n",
            "         7.3153e-03, -2.7719e-02,  2.2355e-03, -2.1606e-02, -5.9960e-02,\n",
            "        -6.9807e-03, -6.5241e-03, -5.8708e-02, -2.4292e-02, -4.9797e-02,\n",
            "        -4.7345e-02, -1.9841e-02, -4.2315e-02, -3.2461e-02, -7.5501e-02,\n",
            "        -5.6416e-02, -3.4017e-02, -2.1488e-02, -1.4311e-02, -2.4219e-02,\n",
            "        -3.7343e-03, -9.8168e-03, -6.9556e-03, -2.1457e-02, -4.1233e-02,\n",
            "        -3.2763e-02, -2.0657e-02, -1.1483e-02,  2.2872e-02, -5.1602e-02,\n",
            "         9.5676e-03, -1.8023e-02, -7.2884e-03, -6.1093e-03, -4.5623e-03,\n",
            "        -7.9790e-03, -3.0514e-02, -2.3381e-03, -1.8526e-02, -5.0738e-02,\n",
            "        -3.0144e-02, -3.0831e-02, -3.2164e-02, -4.8259e-03, -1.7214e-02,\n",
            "        -4.0539e-02, -3.3613e-02, -3.7703e-02, -3.8342e-02, -1.1953e-03,\n",
            "         9.0219e-03,  1.3608e-02, -2.5089e-02, -3.3838e-02,  2.1427e-02,\n",
            "         2.4303e-03, -1.4557e-02, -7.3272e-03, -1.5014e-03, -1.1698e-02,\n",
            "         4.1477e-02, -4.6417e-02, -2.0135e-02, -2.7960e-02,  2.8301e-02,\n",
            "        -5.1567e-04, -3.2665e-02, -4.0946e-02, -1.0468e-02, -1.8228e-03,\n",
            "        -1.4548e-02, -2.1489e-02, -2.6937e-02,  4.4439e-02, -4.0518e-02,\n",
            "        -3.5604e-03,  4.8816e-02, -2.8948e-02, -6.7078e-02, -4.9215e-02,\n",
            "        -2.4759e-02, -3.9852e-02, -4.9563e-03, -4.7032e-02, -3.3995e-02,\n",
            "         1.3151e-02,  6.2219e-03,  2.0080e-02, -4.4041e-02, -3.7491e-02,\n",
            "        -2.3697e-03, -2.6785e-02,  2.2303e-02, -1.8317e-02, -3.2040e-02,\n",
            "        -4.5418e-02,  1.2139e-03, -4.0944e-02, -6.2817e-02,  1.6312e-02,\n",
            "        -2.2214e-02, -2.9649e-02, -3.2141e-02, -5.8369e-04, -3.1678e-02,\n",
            "         1.5912e-03,  4.2378e-03, -3.4981e-03,  7.6575e-03,  1.0887e-02,\n",
            "        -1.2031e-02,  2.8911e-02, -8.1871e-03, -3.3833e-02, -2.4995e-02,\n",
            "         3.5961e-03, -3.8709e-02,  2.5185e-02, -1.0555e-02,  6.4314e-03,\n",
            "         2.9169e-02,  5.5636e-03, -5.2038e-02, -3.4087e-02, -1.3051e-02,\n",
            "        -3.0214e-02,  3.4490e-02, -4.6574e-02, -1.1607e-02,  6.3618e-03,\n",
            "        -3.3242e-02,  2.6094e-03,  1.1715e-02, -1.3506e-02, -3.0005e-02,\n",
            "        -2.0536e-02,  2.5464e-02, -1.8725e-02, -3.2116e-02, -5.8499e-03,\n",
            "         1.0172e-02, -3.2648e-02, -2.4861e-02, -2.8815e-02, -4.1264e-02,\n",
            "        -1.5028e-02, -9.9183e-03, -4.5743e-03, -4.7402e-02,  7.2667e-03,\n",
            "        -3.7625e-02, -1.6859e-02, -3.0019e-05,  2.2051e-02, -5.6266e-02,\n",
            "        -1.9655e-02, -3.6326e-02, -3.5556e-02, -4.0927e-02, -2.1443e-03,\n",
            "        -2.1205e-02, -4.4029e-02,  1.7207e-02,  1.8372e-02, -5.3607e-02,\n",
            "        -4.2329e-02, -4.5909e-02,  2.5197e-02, -5.1460e-02, -2.6192e-02,\n",
            "        -3.8453e-02, -2.0842e-02,  1.3260e-02, -2.7994e-02,  5.5478e-04,\n",
            "        -2.9529e-02, -3.7182e-02, -7.1649e-03,  2.0550e-02, -2.2322e-02,\n",
            "        -4.7242e-02,  1.8283e-02,  2.6231e-02, -2.0541e-02, -1.3071e-02,\n",
            "        -4.8185e-03, -1.2360e-03, -2.0964e-02,  1.4946e-02, -1.5792e-02,\n",
            "        -3.0031e-02, -4.0108e-02, -2.2358e-02, -1.6552e-02, -6.3174e-03,\n",
            "         3.5171e-03, -5.9059e-03, -5.9447e-02, -5.4635e-02, -3.3636e-02,\n",
            "        -7.7243e-03,  8.9392e-03,  6.9644e-03,  1.5618e-02,  1.3654e-02,\n",
            "        -2.9546e-02, -1.2496e-02,  2.9613e-02,  4.1765e-02,  7.7287e-03,\n",
            "        -5.3496e-02, -8.8178e-03,  7.4828e-04, -5.0702e-02, -2.0254e-02,\n",
            "        -5.6750e-04, -4.3538e-02, -3.4478e-02, -5.3648e-02,  4.3115e-03,\n",
            "        -6.5594e-02, -3.8745e-02, -2.4493e-02, -5.4640e-02, -3.2238e-02,\n",
            "        -5.3569e-02, -4.3170e-02, -1.4027e-02,  6.1450e-02, -2.3438e-02,\n",
            "        -5.1565e-03, -4.8406e-04,  1.0383e-02, -4.1854e-03, -4.6447e-02,\n",
            "         5.5716e-03, -1.0719e-02, -3.4483e-02, -5.5556e-02, -7.5205e-02,\n",
            "        -5.1638e-02, -3.5228e-02, -4.4998e-03, -2.5239e-02, -4.7481e-02,\n",
            "        -9.4691e-03,  2.1808e-02, -5.4332e-02, -2.7838e-02, -5.5129e-02,\n",
            "        -1.3595e-02, -1.4248e-03, -5.5812e-02, -4.2307e-02, -2.4651e-02,\n",
            "        -2.8087e-02, -2.5539e-02, -2.3264e-02,  1.1205e-02, -3.0507e-02,\n",
            "        -2.2192e-02, -2.6329e-02, -2.0520e-02, -3.0403e-02, -4.6923e-02,\n",
            "         1.0128e-02, -3.1532e-02, -5.8244e-02, -3.0498e-02, -7.5201e-03,\n",
            "        -1.4116e-02, -2.4493e-02, -1.2573e-02, -4.8288e-04, -5.7587e-02,\n",
            "        -2.3016e-03, -1.0658e-02, -4.2306e-02, -3.8385e-02, -2.7239e-03,\n",
            "        -3.0263e-02, -1.9869e-02, -5.3090e-02, -8.5992e-03, -7.0442e-02,\n",
            "         3.3383e-02,  8.7151e-03, -3.9903e-02, -4.0140e-02,  1.2343e-02,\n",
            "        -3.7364e-02,  6.3775e-03, -2.1373e-02, -1.3347e-02, -8.7473e-03,\n",
            "        -4.0553e-02,  3.6550e-03, -2.7848e-02, -2.9560e-02, -5.6498e-02,\n",
            "        -1.7811e-02, -3.7422e-02, -2.5405e-02, -3.7266e-02, -1.1039e-02,\n",
            "        -1.1755e-02,  3.4041e-03, -4.8261e-02, -6.7056e-03,  3.2365e-03,\n",
            "        -3.9572e-02,  2.0268e-02,  4.8448e-03,  6.5900e-03, -3.4021e-02,\n",
            "        -3.2263e-02,  1.2578e-02, -2.0239e-02,  3.1945e-02, -7.9978e-03,\n",
            "        -5.0851e-02, -5.0714e-02,  1.0731e-02, -4.2558e-02, -9.9571e-04,\n",
            "        -4.6242e-02, -5.1718e-02, -3.8860e-02, -3.2681e-02,  2.6028e-02,\n",
            "        -2.1275e-02,  1.5761e-02, -1.2478e-02,  3.0678e-02, -1.7630e-02,\n",
            "        -2.0939e-02, -4.3362e-03, -4.2439e-02, -7.0778e-02, -4.3847e-02,\n",
            "        -2.3963e-02, -5.5636e-03, -3.2127e-02, -2.7317e-02, -2.2425e-02,\n",
            "        -1.4265e-02, -2.9110e-03,  8.6671e-03, -2.8917e-02, -3.8503e-02,\n",
            "        -4.7464e-02,  3.1910e-02,  6.3825e-03, -1.7392e-02, -5.2009e-02,\n",
            "         9.9586e-05, -3.0520e-02,  3.3100e-03,  8.9493e-03, -3.9853e-02,\n",
            "        -3.5150e-02,  5.3235e-03,  1.2292e-02, -4.3951e-02, -5.8591e-02,\n",
            "        -1.9603e-02,  6.3447e-03, -4.1241e-02, -3.4671e-02, -1.3168e-02,\n",
            "        -3.5558e-02,  2.3476e-02,  3.5946e-03, -1.8676e-02,  9.4152e-03,\n",
            "        -5.9567e-02, -1.0702e-03, -7.5866e-02,  4.7734e-02, -1.9372e-02,\n",
            "        -5.1399e-03, -5.8593e-04, -2.4067e-02, -3.4162e-02, -4.2404e-02,\n",
            "         5.8074e-03, -5.9651e-03, -2.8065e-02, -1.4118e-02, -4.1859e-02,\n",
            "        -2.6447e-02,  1.8147e-02, -1.3245e-02, -4.4762e-02, -4.2659e-02,\n",
            "         1.3599e-02, -2.7460e-02, -2.3828e-02, -2.4241e-02, -3.2447e-02,\n",
            "        -3.6168e-02, -6.4296e-02, -4.5151e-02, -3.1250e-02, -2.4418e-02,\n",
            "        -3.5336e-02, -1.4020e-02,  9.4742e-03, -3.1751e-02, -4.8225e-02,\n",
            "         6.9447e-03, -3.1187e-02, -2.4836e-02, -1.2523e-02, -3.6429e-02,\n",
            "        -1.8629e-02, -5.0575e-02,  1.0169e-02, -4.9300e-02, -1.7903e-03,\n",
            "         9.0519e-03,  4.1940e-03]), tensor([[ 0.0379, -0.0158, -0.0381,  ...,  0.0284,  0.0202,  0.0266],\n",
            "        [ 0.0052,  0.0621, -0.0354,  ..., -0.0896,  0.0124, -0.0060],\n",
            "        [-0.0138,  0.0473, -0.0594,  ...,  0.0537,  0.0375,  0.0060],\n",
            "        ...,\n",
            "        [-0.0098,  0.1043, -0.0174,  ..., -0.0911,  0.0636, -0.0119],\n",
            "        [-0.0039,  0.0661,  0.0060,  ..., -0.0097,  0.0248, -0.0341],\n",
            "        [ 0.0509,  0.0418,  0.0265,  ..., -0.0198,  0.0924,  0.0369]]), tensor([-0.0083,  0.0739, -0.0221, -0.0275,  0.0613,  0.0135,  0.0588,  0.0509,\n",
            "         0.0273,  0.1373,  0.0413,  0.0654, -0.0217,  0.1187,  0.0371,  0.0187,\n",
            "        -0.0744,  0.0142, -0.0340, -0.0079, -0.0548,  0.0666,  0.1024,  0.0163,\n",
            "         0.0226, -0.0638,  0.0051, -0.0083, -0.0048, -0.0018,  0.1222,  0.0211,\n",
            "        -0.0700,  0.0513, -0.0032,  0.0220,  0.0005, -0.0263, -0.0147, -0.0224,\n",
            "        -0.0209, -0.0256,  0.0838, -0.0289, -0.0555, -0.0058, -0.0082,  0.0233,\n",
            "        -0.0980,  0.0442,  0.0082, -0.0349, -0.0128,  0.0658,  0.0328, -0.0347,\n",
            "         0.0223,  0.0274,  0.0875,  0.0326,  0.0721, -0.0104, -0.0400, -0.0737,\n",
            "        -0.1086,  0.0128,  0.0627,  0.0400, -0.0451, -0.0299,  0.0721,  0.0387,\n",
            "         0.0022,  0.0085,  0.0140,  0.0251,  0.0527, -0.0672, -0.0330, -0.0229,\n",
            "         0.0137,  0.0758,  0.0314,  0.0346,  0.0686,  0.0200, -0.0276, -0.0310,\n",
            "        -0.0293,  0.0858,  0.0087,  0.0557,  0.0563, -0.0378, -0.0720, -0.0415,\n",
            "         0.0309,  0.0128,  0.0224, -0.0615,  0.0468,  0.1360,  0.0246, -0.0246,\n",
            "         0.0011, -0.0318,  0.0703, -0.0439, -0.0533, -0.0122, -0.0151,  0.0554,\n",
            "         0.0156,  0.0002,  0.0499,  0.0328, -0.0338,  0.0066, -0.0796, -0.0039,\n",
            "        -0.0367, -0.0393,  0.0371,  0.0123, -0.0440,  0.0798,  0.0769,  0.0766,\n",
            "         0.0541, -0.0302,  0.0343,  0.0584,  0.0250,  0.0215,  0.0114,  0.0112,\n",
            "        -0.0174,  0.0555, -0.0631,  0.0388,  0.0777,  0.0019, -0.0045,  0.0042,\n",
            "         0.0452, -0.0441, -0.0382, -0.0091,  0.0389,  0.0370,  0.0492,  0.1049,\n",
            "        -0.0606,  0.0109, -0.0231,  0.0433, -0.0294,  0.0429, -0.0641, -0.0408,\n",
            "         0.0333, -0.0096,  0.0053,  0.0089,  0.0110, -0.0546,  0.0522, -0.0691,\n",
            "        -0.0476,  0.0873,  0.0012, -0.0373,  0.0226, -0.0162,  0.0256, -0.0020,\n",
            "        -0.0966,  0.0491,  0.0829, -0.0042,  0.0349,  0.0026, -0.0285,  0.0076,\n",
            "         0.0015, -0.0486,  0.0768, -0.0722,  0.0298,  0.0699, -0.0287,  0.0183,\n",
            "         0.0092,  0.0434,  0.0480,  0.0207, -0.0302,  0.0349, -0.0501,  0.0196,\n",
            "         0.1282,  0.0882,  0.0330, -0.0153,  0.0547,  0.0161,  0.0245,  0.0888,\n",
            "         0.0986,  0.0512,  0.0234, -0.0399,  0.0750,  0.0334, -0.0511, -0.0225,\n",
            "         0.1063, -0.0336,  0.0133,  0.0870,  0.0104, -0.0513,  0.0692,  0.0224,\n",
            "         0.0416,  0.0306,  0.0215,  0.0354, -0.0496,  0.0553,  0.0329,  0.0737,\n",
            "         0.1238,  0.0646,  0.1027,  0.0228,  0.0257, -0.0452,  0.0917,  0.0648,\n",
            "         0.0080, -0.0685,  0.0015,  0.0953,  0.0718,  0.0261,  0.0060,  0.0338,\n",
            "        -0.0086,  0.0635,  0.0938,  0.0200,  0.0566,  0.0549,  0.0304,  0.1256]), tensor([[-0.0390, -0.0370, -0.1003,  ..., -0.0083, -0.0427,  0.0340],\n",
            "        [-0.1096, -0.0140, -0.0199,  ...,  0.0051,  0.0857,  0.0698],\n",
            "        [ 0.0191,  0.1093,  0.0279,  ...,  0.0129,  0.0677,  0.0850],\n",
            "        ...,\n",
            "        [-0.0371,  0.0186,  0.0350,  ...,  0.0263, -0.0182,  0.0555],\n",
            "        [ 0.0173,  0.1046,  0.0074,  ...,  0.1172,  0.0048, -0.0428],\n",
            "        [ 0.0811, -0.0909,  0.0325,  ..., -0.0272,  0.0487, -0.0199]]), tensor([ 0.0424,  0.0863,  0.1018,  0.1185,  0.0651,  0.0986,  0.1582,  0.0557,\n",
            "        -0.0336,  0.0754,  0.2355,  0.0463,  0.0203,  0.0427,  0.1072, -0.0371,\n",
            "         0.0889,  0.0457, -0.0179,  0.0475,  0.1023, -0.0072,  0.0117,  0.0134,\n",
            "        -0.0143,  0.0105,  0.0504,  0.0297,  0.1112,  0.0897, -0.0202,  0.0956,\n",
            "         0.0415,  0.0096,  0.1198,  0.0161,  0.0582,  0.0651,  0.1161,  0.0908,\n",
            "         0.1178,  0.0327,  0.0230,  0.0328, -0.0130,  0.1567, -0.0531,  0.0101,\n",
            "         0.0668,  0.0654,  0.0514,  0.1233,  0.1003,  0.0535, -0.0329,  0.0226,\n",
            "         0.1053,  0.0638,  0.0663,  0.0268, -0.0009, -0.0163, -0.0053, -0.0012,\n",
            "         0.1039,  0.1407,  0.0946,  0.0617, -0.0005,  0.0258,  0.0559,  0.0562,\n",
            "        -0.0014,  0.2615, -0.0416,  0.0058,  0.0328,  0.0275, -0.0254,  0.0318,\n",
            "         0.1691,  0.1391,  0.1249,  0.0282,  0.0744,  0.1662,  0.0916,  0.0062,\n",
            "         0.0500,  0.1379, -0.0031, -0.0184,  0.0135, -0.0027, -0.0005, -0.0488,\n",
            "         0.1024,  0.0690,  0.0890,  0.0557,  0.1706,  0.1321,  0.1113,  0.1251,\n",
            "         0.0664,  0.0361, -0.0237,  0.1284,  0.1241,  0.0451,  0.1485, -0.0144,\n",
            "         0.0085, -0.0735,  0.0610,  0.0439,  0.0599,  0.0576, -0.0082, -0.0122,\n",
            "         0.1613,  0.0492,  0.0358,  0.0887,  0.0301,  0.0446,  0.0384,  0.1336]), tensor([[ 0.0531, -0.0500,  0.0217,  ..., -0.1414, -0.0094,  0.0828],\n",
            "        [ 0.0935,  0.0143, -0.1264,  ..., -0.1165, -0.0953, -0.1062],\n",
            "        [ 0.0663,  0.0533,  0.0600,  ..., -0.0205, -0.0610,  0.0537],\n",
            "        ...,\n",
            "        [-0.1817, -0.0696, -0.0573,  ...,  0.0160, -0.0695, -0.0312],\n",
            "        [-0.0833,  0.0865,  0.0393,  ..., -0.1353,  0.0540, -0.0105],\n",
            "        [-0.1089, -0.1530, -0.0056,  ...,  0.0576,  0.0116,  0.0251]]), tensor([-0.0563, -0.1901,  0.0720,  0.0307, -0.0207, -0.0569,  0.0436, -0.0141,\n",
            "         0.0531, -0.1055])])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li1Xk88wGR_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model\n",
        "torch.save(model.state_dict(), 'checkpoint.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pnaoez1tGiEb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f570150d-1957-4aa3-b739-c043e367b1ac"
      },
      "source": [
        "# load model\n",
        "state_dict = torch.load('checkpoint.pth')\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "odict_keys(['hidden_layers.0.weight', 'hidden_layers.0.bias', 'hidden_layers.1.weight', 'hidden_layers.1.bias', 'hidden_layers.2.weight', 'hidden_layers.2.bias', 'output.weight', 'output.bias'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOOjX3FJGn_s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab06cdf1-5659-485d-8528-2bd3e2e4f0ab"
      },
      "source": [
        "# load model to the network\n",
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNJATyoNGvhK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "8daf6dc3-3381-4f12-c9be-3e91980d7f1a"
      },
      "source": [
        "# Try this\n",
        "model = fc_model.Network(784, 10, [400, 200, 100])\n",
        "# This will throw an error because the tensor sizes are wrong!\n",
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-cc11e1013989>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# This will throw an error because the tensor sizes are wrong!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 777\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    778\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Network:\n\tsize mismatch for hidden_layers.0.weight: copying a param with shape torch.Size([512, 784]) from checkpoint, the shape in current model is torch.Size([400, 784]).\n\tsize mismatch for hidden_layers.0.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([400]).\n\tsize mismatch for hidden_layers.1.weight: copying a param with shape torch.Size([256, 512]) from checkpoint, the shape in current model is torch.Size([200, 400]).\n\tsize mismatch for hidden_layers.1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([200]).\n\tsize mismatch for hidden_layers.2.weight: copying a param with shape torch.Size([128, 256]) from checkpoint, the shape in current model is torch.Size([100, 200]).\n\tsize mismatch for hidden_layers.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([100]).\n\tsize mismatch for output.weight: copying a param with shape torch.Size([10, 128]) from checkpoint, the shape in current model is torch.Size([10, 100])."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sunDg7lGynj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = {'input_size': 784,\n",
        "              'output_size': 10,\n",
        "              'hidden_layers': [each.out_features for each in model.hidden_layers],\n",
        "              'state_dict': model.state_dict()}\n",
        "\n",
        "torch.save(checkpoint, 'checkpoint.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl_gQL_DG6q0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_checkpoint(filepath):\n",
        "    checkpoint = torch.load(filepath)\n",
        "    model = fc_model.Network(checkpoint['input_size'],\n",
        "                             checkpoint['output_size'],\n",
        "                             checkpoint['hidden_layers'])\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jma5U78rG8WD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "24833d32-51f7-4ffc-aa16-52e723aa158c"
      },
      "source": [
        "model = load_checkpoint('checkpoint.pth')\n",
        "print(model)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Network(\n",
            "  (hidden_layers): ModuleList(\n",
            "    (0): Linear(in_features=784, out_features=400, bias=True)\n",
            "    (1): Linear(in_features=400, out_features=200, bias=True)\n",
            "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
            "  )\n",
            "  (output): Linear(in_features=100, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.5)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4otHia_G-Nr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}