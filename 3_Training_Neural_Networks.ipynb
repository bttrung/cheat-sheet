{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_Training Neural Networks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bttrung/secure-private-ai-scholarship/blob/master/3_Training_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdSBCZ366oeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwP04hNq6r4t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b32f252-4edf-44f9-e50b-3c868fbd963e"
      },
      "source": [
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10))\n",
        "\n",
        "# Define the loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Get our data\n",
        "images, labels = next(iter(trainloader))\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Forward pass, get our logits\n",
        "logits = model(images)\n",
        "# Calculate the loss with the logits and the labels\n",
        "loss = criterion(logits, labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3058, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "186tRohT6y1I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2329d681-5d87-4484-eefc-b26b38166830"
      },
      "source": [
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "# Define the loss\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "# Get our data\n",
        "images, labels = next(iter(trainloader))\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Forward pass, get our log-probabilities\n",
        "logps = model(images)\n",
        "# Calculate the loss with the logps and the labels\n",
        "loss = criterion(logps, labels)\n",
        "\n",
        "print(loss)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.3493, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSxJZ80b74J6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "495d7da9-141b-44d4-9fef-fecfc55a54fe"
      },
      "source": [
        "x = torch.randn(2,2, requires_grad=True)\n",
        "print(x)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.5499, -1.3530],\n",
            "        [ 0.7348,  1.3376]], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYOk61QQ760p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6f93c5ab-bc71-4450-c195-1215ce75d225"
      },
      "source": [
        "y = x**2\n",
        "print(y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3024, 1.8306],\n",
            "        [0.5400, 1.7891]], grad_fn=<PowBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgridXz_78Xa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84737abb-883e-4834-9e4a-63ee65da7c4c"
      },
      "source": [
        "## grad_fn shows the function that generated this variable\n",
        "print(y.grad_fn)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PowBackward0 object at 0x7f33585f3240>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dy6Hua2N7_gy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14ecba9b-7c35-45a0-c81d-ed0c63993d11"
      },
      "source": [
        "z = y.mean()\n",
        "print(z)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.1155, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQhZ_u-58Bhh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d6e7374-adab-42b1-9563-91b75078dc4e"
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvYse1Sh8DkK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0f1e5fcc-f5d1-4be6-ddbe-7d8737877b77"
      },
      "source": [
        "z.backward()\n",
        "print(x.grad)\n",
        "print(x/2)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.2749, -0.6765],\n",
            "        [ 0.3674,  0.6688]])\n",
            "tensor([[ 0.2749, -0.6765],\n",
            "        [ 0.3674,  0.6688]], grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFFO2-FH8FS5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "images, labels = next(iter(trainloader))\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "logps = model(images)\n",
        "loss = criterion(logps, labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49N4_VNa8IIa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "dd6d1386-7a9a-4c0d-fabf-76f9e919c4f0"
      },
      "source": [
        "print('Before backward pass: \\n', model[0].weight.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('After backward pass: \\n', model[0].weight.grad)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before backward pass: \n",
            " None\n",
            "After backward pass: \n",
            " tensor([[-0.0019, -0.0019, -0.0019,  ..., -0.0019, -0.0019, -0.0019],\n",
            "        [ 0.0004,  0.0004,  0.0004,  ...,  0.0004,  0.0004,  0.0004],\n",
            "        [ 0.0017,  0.0017,  0.0017,  ...,  0.0017,  0.0017,  0.0017],\n",
            "        ...,\n",
            "        [-0.0010, -0.0010, -0.0010,  ..., -0.0010, -0.0010, -0.0010],\n",
            "        [-0.0020, -0.0020, -0.0020,  ..., -0.0020, -0.0020, -0.0020],\n",
            "        [-0.0002, -0.0002, -0.0002,  ..., -0.0002, -0.0002, -0.0002]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44zQ2-8v8KdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "# Optimizers require the parameters to optimize and a learning rate\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b6WbV7s8NV6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "374a9296-0aef-4c5d-9e16-bd7062bc238b"
      },
      "source": [
        "print('Initial weights - ', model[0].weight)\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "images.resize_(64, 784)\n",
        "\n",
        "# Clear the gradients, do this because gradients are accumulated\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Forward pass, then backward pass, then update weights\n",
        "output = model.forward(images)\n",
        "loss = criterion(output, labels)\n",
        "loss.backward()\n",
        "print('Gradient -', model[0].weight.grad)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial weights -  Parameter containing:\n",
            "tensor([[ 0.0240, -0.0326, -0.0271,  ..., -0.0255,  0.0013,  0.0168],\n",
            "        [-0.0209, -0.0190,  0.0291,  ...,  0.0230, -0.0284,  0.0355],\n",
            "        [ 0.0290, -0.0160,  0.0302,  ...,  0.0129, -0.0087, -0.0228],\n",
            "        ...,\n",
            "        [ 0.0303,  0.0328, -0.0256,  ...,  0.0103, -0.0006,  0.0016],\n",
            "        [ 0.0204,  0.0219, -0.0220,  ..., -0.0119,  0.0042, -0.0002],\n",
            "        [-0.0020,  0.0214,  0.0063,  ..., -0.0005,  0.0295, -0.0082]],\n",
            "       requires_grad=True)\n",
            "Gradient - tensor([[ 0.0024,  0.0024,  0.0024,  ...,  0.0024,  0.0024,  0.0024],\n",
            "        [-0.0006, -0.0006, -0.0006,  ..., -0.0006, -0.0006, -0.0006],\n",
            "        [ 0.0014,  0.0014,  0.0014,  ...,  0.0014,  0.0014,  0.0014],\n",
            "        ...,\n",
            "        [ 0.0050,  0.0050,  0.0050,  ...,  0.0050,  0.0050,  0.0050],\n",
            "        [-0.0019, -0.0019, -0.0019,  ..., -0.0019, -0.0019, -0.0019],\n",
            "        [ 0.0007,  0.0007,  0.0007,  ...,  0.0007,  0.0007,  0.0007]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVtq2qE18PQi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "be12ec56-5c58-4722-91fa-737e173e5a2c"
      },
      "source": [
        "# Take an update step and few the new weights\n",
        "optimizer.step()\n",
        "print('Updated weights - ', model[0].weight)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated weights -  Parameter containing:\n",
            "tensor([[ 0.0240, -0.0326, -0.0271,  ..., -0.0255,  0.0012,  0.0168],\n",
            "        [-0.0208, -0.0190,  0.0291,  ...,  0.0230, -0.0284,  0.0355],\n",
            "        [ 0.0290, -0.0160,  0.0302,  ...,  0.0129, -0.0088, -0.0229],\n",
            "        ...,\n",
            "        [ 0.0303,  0.0327, -0.0257,  ...,  0.0102, -0.0007,  0.0015],\n",
            "        [ 0.0204,  0.0219, -0.0220,  ..., -0.0119,  0.0042, -0.0001],\n",
            "        [-0.0020,  0.0214,  0.0063,  ..., -0.0006,  0.0295, -0.0082]],\n",
            "       requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HPHayeX8Rcj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "86183df0-0166-4af0-da12-d7e84c0547ad"
      },
      "source": [
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "    \n",
        "        # TODO: Training pass\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model.forward(images)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training loss: 1.8835779194638673\n",
            "Training loss: 0.8339055864605059\n",
            "Training loss: 0.5128205874835504\n",
            "Training loss: 0.4209383172966016\n",
            "Training loss: 0.3779910124504744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwGpucvO8ViT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "72c644c3-1207-4f26-d202-0f42f5e82f70"
      },
      "source": [
        "%matplotlib inline\n",
        "import helper\n",
        "\n",
        "images, labels = next(iter(trainloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logps = model.forward(img)\n",
        "\n",
        "# Output of the network are logits, need to take softmax for probabilities\n",
        "ps = torch.exp(logps)\n",
        "helper.view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAADjCAYAAADQWoDbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDChJ0iD9P6C+vMW9UDCyAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmddToSP8ijy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}